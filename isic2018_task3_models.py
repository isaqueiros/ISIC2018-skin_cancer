# -*- coding: utf-8 -*-
"""ISIC2018_Task3_Models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rQUPJts2IBil4EFcV-zq8N_B038IRtdZ

# Models

## Libraries Import
"""

import tensorflow as tf
import keras
from keras import layers, models
from tensorflow.keras.applications import EfficientNetB0, EfficientNetB4, EfficientNetB7, EfficientNetV2M, ResNet50V2, ResNet152V2, InceptionV3, DenseNet121, DenseNet201

"""## Models Definition"""

class BaseModel:
  def __init__(self):
    CHANNELS = 3

  # Custom CNN
  def customCNN(self):
    base_model = models.Sequential([
        # Convolution and Pooling Layers (3 layers of each)
        layers.Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'),

        layers.Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'),

        layers.Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'),

        # Flatten output into a 1-dimensional tensor
        layers.Flatten(),

        # Fully-Connected Layers
        layers.Dense(128, activation="relu"),
        layers.Dropout(0.2),
        layers.Dense(64, activation="relu"),
        layers.Dropout(0.2),
        layers.Dense(NUM_CLASSES, activation="softmax"),
        ])
    return base_model

  # EfficientNet-B0
  def modelENB0(self, HEIGHT, WIDTH):
    base_model = EfficientNetB0(
        include_top=False,
        weights="imagenet", # transfer learning
        classes=NUM_CLASSES,
        input_shape=(HEIGHT, WIDTH, CHANNELS),
        )
    return base_model

  # EfficientNet-B4
  def modelENB4(self, HEIGHT, WIDTH):
    base_model = EfficientNetB4(
        include_top=False,
        weights="imagenet", # transfer learning
        classes=NUM_CLASSES,
        input_shape=(HEIGHT, WIDTH, CHANNELS),
        name="efficientnetb4",
        )
    return base_model

  # EfficientNet-B7
  def modelENB7(self, HEIGHT, WIDTH):
    base_model = EfficientNetB7(
        include_top=False,
        weights="imagenet", # transfer learning
        classes=NUM_CLASSES,
        input_shape=(HEIGHT, WIDTH, CHANNELS),
        name="efficientnetb7",
        )
    return base_model

  # EfficientNetNV2-M
  def modelNV2M(self, HEIGHT, WIDTH):
    base_model = EfficientNetV2M(
        include_top=False,
        weights="imagenet", # transfer learning
        classes=NUM_CLASSES,
        input_shape=(HEIGHT, WIDTH, CHANNELS),
        name="efficientnetv2-m",
        )
    return base_model

  # ResNet50V2
  def modelRN50V2(self, HEIGHT, WIDTH):
    base_model = ResNet50V2(
        include_top=False,
        weights="imagenet", # transfer learning
        classes=NUM_CLASSES,
        input_shape=(HEIGHT, WIDTH, CHANNELS),
        name="resnet50v2",
        )
    return base_model

  # ResNet152V2
  def modelRN152V2(self, HEIGHT, WIDTH):
    base_model = ResNet152V2(
        include_top=False,
        weights="imagenet", # transfer learning
        classes=NUM_CLASSES,
        input_shape=(HEIGHT, WIDTH, CHANNELS),
        name="resnet152v2",
        )
    return base_model

  # InceptionV3
  def modelINV3(self, HEIGHT, WIDTH):
    base_model = InceptionV3(
        include_top=False,
        weights="imagenet", # transfer learning
        classes=NUM_CLASSES,
        input_shape=(HEIGHT, WIDTH, CHANNELS),
        name="inception_v3",
        )
    return base_model

  # DenseNet121
  def modelDN121(self, HEIGHT, WIDTH):
    base_model = DenseNet121(
        include_top=False,
        weights="imagenet", # transfer learning
        classes=NUM_CLASSES,
        input_shape=(HEIGHT, WIDTH, CHANNELS),
        name="densenet121",
        )
    return base_model

  # DenseNet201
  def modelDN201(self, HEIGHT, WIDTH):
    base_model = DenseNet201(
        include_top=False,
        weights="imagenet", # transfer learning
        classes=NUM_CLASSES,
        input_shape=(HEIGHT, WIDTH, CHANNELS),
        name="densenet201",
        )
    return base_model

  def finalLayer(self, NUM_CLASSES):
    finalLayer = models.Sequential([
        layers.GlobalAveragePooling2D(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(NUM_CLASSES, activation='softmax')
        ])
    return finalLayer